# Lululemon Athletica
## Machine learning Multi-Image Classification
<img width="1107" alt="Unknown" src="https://user-images.githubusercontent.com/109767578/212406975-c552819f-c1c8-42ef-b6c3-612ce6a0d9b0.png">
Author: Edward Juarez

## Introduction
For this capstone project, I collaborated with a hypothetical client, the Chief Brand Officer, and the Lululemon marketing department. The project involved spearheading a robust global marketing campaign across diverse social media platforms. The primary goal was to promote inclusivity and attract new customers, particularly those who might feel hesitant to embark on their yoga journey—whether in a studio or at home.

The strategy included implementing a reward system to encourage individuals to share photos featuring five specific yoga poses specified by Lululemon. This initiative not only aims to incentivize participation but also serves as a means of demystifying yoga for those with limited or no prior knowledge of poses.

Participants have the opportunity to contribute to a growing social network by sharing their images, providing real-life examples of how each pose is executed. This not only fosters a sense of community but also creates a valuable resource for individuals seeking clarity on various yoga postures.

Furthermore, the collected data serves dual purposes—acting as a tool for customer engagement and providing a mechanism for assessing the accuracy of pose execution. This ensures that participants receive constructive feedback on their yoga practice.

Anticipating a substantial influx of submissions, the project is poised to generate extensive feedback, requiring efficient time management and employee coordination to handle the volume effectively. This initiative not only aligns with Lululemon's commitment to customer engagement but also demonstrates the brand's innovative approach to fostering a supportive and informed yoga community.

## Business Objective
The primary objective of this project is to develop a sophisticated multi-image classification model utilizing artificial intelligence algorithms, specifically a multi-layer Convolutional Neural Network. The aim is to enable the accurate identification of five distinct yoga poses, namely the downward dog pose, tree pose, plank pose, goddess pose, and the warrior 2 pose.

The output generated by this model holds significant value as it provides a reliable mechanism for identifying yoga poses. This capability not only serves the immediate goal of pose recognition but also contributes to the accumulation of dependable data, enhancing our understanding of yoga postures. This business objective aligns with the broader vision of leveraging advanced technology to create a valuable tool for both yoga practitioners and those seeking accurate pose identification.

## Data Understanding
The dataset utilized for this project was obtained from Kaggle, and you can access it here. This dataset specifically focuses on yoga poses and comprises a total of 1550 images, each containing RGB color values along with an alpha channel indicating color opacity.

Our analysis concentrated on 1550 static images distributed across five distinct image classes. The objective was to leverage this dataset to develop a robust multi-image classification model. The model's purpose is to assist the marketing department in accurately identifying various image classes relevant to yoga poses. Through comprehensive analysis and modeling, we aimed to enhance the department's capability to discern and categorize images effectively.

<img width="1263" alt="Screen Shot 2023-01-13 at 3 17 07 PM" src="https://user-images.githubusercontent.com/109767578/212411662-255c6454-c525-40b8-934f-bf184c3e0513.png">

`Downward dog pose`  
`Tree pose`  
`Plank pose`  
`Goddess pose`  
`Warrior 2 pose`  

## Data Preparation
The initial phase involved importing essential Python libraries for machine learning and data manipulation. Subsequently, the dataset was loaded and partitioned into training, test, and validation sets. Given the dataset's relatively small size, an 80-20 split was applied to the training dataset, allocating 80% for training and reserving the remaining 20% as an alternative set for validation purposes.

To prepare the image data for model training, a rescaling operation was performed, specifically setting Rescale=1./255. This transformation converts pixel values from the original range of [0,255] to a normalized range of [0,1]. This process is commonly referred to as normalizing the input. By ensuring that all images share the same scale, ranging from 0 to 1, the model treats each image contribution more uniformly during the optimization process, promoting fair and consistent learning across all images.

The exploration of the dataset involved inspecting the class_indices, providing insights into the categorical labels of the dataset classes. Additionally, the array_to_img function was systematically applied to generate visual representations of random images within the dataset. This visualization step facilitated a closer examination of the dataset's content and structure, aiding in the understanding of the input images and potential challenges posed by the dataset's variability.

## Modeling
The modeling process commenced with the creation of a baseline model, initially consisting of a single dense layer. To enhance the model's capability for image classification, convolutional layers were incrementally introduced, transforming it into a Convolutional Neural Network (CNN). However, during the initial stages, the model exhibited signs of underfitting, prompting further refinement.

To address the underfitting issue, augmentation techniques were applied. Augmentation plays a crucial role in extracting more information from a limited dataset, potentially improving model performance. Despite the inclusion of augmentation, the model still demonstrated underfitting. Consequently, additional dense layers and convolutional layers were incorporated, and adjustments to hyperparameters and filter configurations were made.

This iterative process inadvertently led to the development of a highly complex model that exhibited signs of overfitting. To mitigate overfitting, dropout layers were strategically introduced. Dropout layers aid in preventing the model from relying too heavily on specific nodes during training, promoting a more generalized and robust model.

The final model achieved an Accuracy Score of 86 on the validation dataset. The architecture of the final model involved a sequence of convolutional layers followed by max-pooling operations, repeated multiple times with parameter adjustments. Towards the end of the architecture, dropout layers were introduced to counter overfitting observed in earlier iterations. The culmination of these architectural adjustments and regularization techniques resulted in an effective and well-balanced model for image classification.


<img width="750" alt="Final_mod_Architecture" src="https://user-images.githubusercontent.com/109767578/212430533-58dc963d-08c0-4155-8806-c5ea206b2a28.png">

This shows a comparison of the Baseline Model and Final Models' accuracy scores.

<img width="1109" alt="baseline final_chart" src="https://user-images.githubusercontent.com/109767578/212431008-41e40b8c-495a-48ef-a3f2-05b4879d2338.png">

## Evaluation
Following our model's evaluation on unseen data, we achieved an impressive accuracy score of 91%. This score provides valuable insights into how well our model may generalize to real-world scenarios. As previously highlighted, we selected accuracy as our primary metric for model evaluation.

To provide a detailed assessment of our model's performance, we present a confusion matrix illustrating the classifications. In the matrix, the diagonals represent correct predictions, showcasing a high level of accuracy in our model. Notably, the most prevalent error involves the misidentification of goddess pose as warrior 2 pose. This challenge arises due to the inherent similarity in formation when the poses are inverted, underscoring the complexity of distinguishing between certain yoga postures.

Overall, our model has demonstrated strong performance, with the provided accuracy score serving as a robust indicator of its effectiveness in making accurate predictions on previously unseen data.

<img width="706" alt="Conf_MatrX" src="https://user-images.githubusercontent.com/109767578/212432106-9cb17f7f-7843-4a8e-8773-9ef54f28bb61.png">

## Conclusion

What does this groundbreaking achievement mean for Lululemon? With a commendable level of accuracy attained, Lululemon now possesses the capability to precisely identify various yoga poses. This technological advancement translates into significant benefits for the brand and its customer base.

Lululemon can leverage this valuable information to enhance customer engagement and empower users with personalized feedback on the accuracy of their pose execution. This tailored guidance not only promotes a deeper connection with customers but also aligns with industry trends emphasizing individualized user experiences.

Beyond the immediate benefits, Lululemon gains access to reliable data that opens new avenues for sales growth opportunities. This data-driven approach enables targeted marketing strategies, personalized product recommendations, and a heightened understanding of customer preferences. The integration of such insights can potentially elevate Lululemon's position in the market by delivering curated experiences tailored to individual needs.

Simultaneously, the data collected during this process serves as a valuable resource for future projects. One such application involves segmentation, facilitating virtual try-ons for clothing, accessories, and other items. This advancement in user experience not only aligns with current industry trends but also positions Lululemon at the forefront of innovation within the retail and fitness sectors.

Additionally, the capabilities unlocked by this model extend to face recognition, paving the way for contactless payments using facial recognition as a secure and convenient proof of identity. This aligns seamlessly with the evolving landscape of technology-driven retail experiences and further reinforces Lululemon's commitment to staying at the forefront of industry advancements.

In summary, the successful implementation of this technology not only enhances Lululemon's yoga pose identification capabilities but also opens doors to a multitude of innovative possibilities, reinforcing the brand's position as a leader in the intersection of fashion, technology, and personalized customer experiences.
## For More Information
Please review my full analysis in [my Jupyter Notebook](https://github.com/DSEDDIE/lulu_multi_image_proj/blob/main/Lululemon%20final%20notebook.ipynb) or my [presentation](https://github.com/DSEDDIE/lulu_multi_image_proj/blob/main/Presentation.pdf).
 
For any additional questions, please contact Edward Juarez | mr.edwardjuarez@gmail.com

## Repository Structure
```
├── DATASET                         <- Both sourced externally and generated from code
├── IMAGES                          <- Both sourced externally and generated from code
├── .gitignore                      <- list of ignore files
├── LICENSE                         <- License
├── Lululemon final notebook.ipynb  <- Narrative documentation of analysis in Jupyter notebook
├── Presentation.pdf                <- PDF version of project presentation
└── README.md.                      <- README for reviewers of this project

```


 



 
